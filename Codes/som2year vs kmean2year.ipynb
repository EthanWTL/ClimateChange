{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dc4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.ma.core import ceil\n",
    "from scipy.spatial import distance #distance calculation\n",
    "from sklearn.preprocessing import MinMaxScaler #normalisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score #scoring\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import animation, colors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214bc26e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>thrid</th>\n",
       "      <th>Forth</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11133.0</td>\n",
       "      <td>11132.0</td>\n",
       "      <td>11130.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>11130.0</td>\n",
       "      <td>11131.0</td>\n",
       "      <td>11134.0</td>\n",
       "      <td>11137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11046.0</td>\n",
       "      <td>11056.0</td>\n",
       "      <td>11073.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11679.0</td>\n",
       "      <td>11676.0</td>\n",
       "      <td>11672.0</td>\n",
       "      <td>11668.0</td>\n",
       "      <td>11663.0</td>\n",
       "      <td>11658.0</td>\n",
       "      <td>11654.0</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>11643.0</td>\n",
       "      <td>11638.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11604.0</td>\n",
       "      <td>11613.0</td>\n",
       "      <td>11626.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11310.0</td>\n",
       "      <td>11302.0</td>\n",
       "      <td>11296.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11297.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11284.0</td>\n",
       "      <td>11306.0</td>\n",
       "      <td>11336.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11310.0</td>\n",
       "      <td>11302.0</td>\n",
       "      <td>11296.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11297.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11284.0</td>\n",
       "      <td>11306.0</td>\n",
       "      <td>11336.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11383.0</td>\n",
       "      <td>11369.0</td>\n",
       "      <td>11358.0</td>\n",
       "      <td>11349.0</td>\n",
       "      <td>11343.0</td>\n",
       "      <td>11337.0</td>\n",
       "      <td>11333.0</td>\n",
       "      <td>11332.0</td>\n",
       "      <td>11331.0</td>\n",
       "      <td>11333.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11279.0</td>\n",
       "      <td>11296.0</td>\n",
       "      <td>11318.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>CL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>12279.0</td>\n",
       "      <td>12299.0</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>12346.0</td>\n",
       "      <td>12353.0</td>\n",
       "      <td>12356.0</td>\n",
       "      <td>12353.0</td>\n",
       "      <td>12348.0</td>\n",
       "      <td>12339.0</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12362.0</td>\n",
       "      <td>12367.0</td>\n",
       "      <td>12369.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>12389.0</td>\n",
       "      <td>12394.0</td>\n",
       "      <td>12407.0</td>\n",
       "      <td>12417.0</td>\n",
       "      <td>12421.0</td>\n",
       "      <td>12426.0</td>\n",
       "      <td>12428.0</td>\n",
       "      <td>12429.0</td>\n",
       "      <td>12429.0</td>\n",
       "      <td>12428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>12413.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>12419.0</td>\n",
       "      <td>12423.0</td>\n",
       "      <td>12420.0</td>\n",
       "      <td>12420.0</td>\n",
       "      <td>12419.0</td>\n",
       "      <td>12416.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>12417.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12406.0</td>\n",
       "      <td>12402.0</td>\n",
       "      <td>12404.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>12318.0</td>\n",
       "      <td>12328.0</td>\n",
       "      <td>12336.0</td>\n",
       "      <td>12342.0</td>\n",
       "      <td>12344.0</td>\n",
       "      <td>12344.0</td>\n",
       "      <td>12342.0</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>12334.0</td>\n",
       "      <td>12328.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12366.0</td>\n",
       "      <td>12375.0</td>\n",
       "      <td>12391.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>12297.0</td>\n",
       "      <td>12310.0</td>\n",
       "      <td>12327.0</td>\n",
       "      <td>12331.0</td>\n",
       "      <td>12326.0</td>\n",
       "      <td>12310.0</td>\n",
       "      <td>12318.0</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>12337.0</td>\n",
       "      <td>12352.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12423.0</td>\n",
       "      <td>12419.0</td>\n",
       "      <td>12413.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NROI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3        4        5        6        7  \\\n",
       "0    11133.0  11132.0  11130.0  11129.0  11129.0  11129.0  11130.0  11131.0   \n",
       "1    11679.0  11676.0  11672.0  11668.0  11663.0  11658.0  11654.0  11648.0   \n",
       "2    11310.0  11302.0  11296.0  11292.0  11289.0  11287.0  11287.0  11289.0   \n",
       "3    11310.0  11302.0  11296.0  11292.0  11289.0  11287.0  11287.0  11289.0   \n",
       "4    11383.0  11369.0  11358.0  11349.0  11343.0  11337.0  11333.0  11332.0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "732  12279.0  12299.0  12324.0  12346.0  12353.0  12356.0  12353.0  12348.0   \n",
       "733  12389.0  12394.0  12407.0  12417.0  12421.0  12426.0  12428.0  12429.0   \n",
       "734  12419.0  12423.0  12420.0  12420.0  12419.0  12416.0  12415.0  12412.0   \n",
       "735  12318.0  12328.0  12336.0  12342.0  12344.0  12344.0  12342.0  12338.0   \n",
       "736  12297.0  12310.0  12327.0  12331.0  12326.0  12310.0  12318.0  12324.0   \n",
       "\n",
       "           8        9  ...      222      223      224    225   226  first  \\\n",
       "0    11134.0  11137.0  ...  11046.0  11056.0  11073.0   94.0  17.0      1   \n",
       "1    11643.0  11638.0  ...  11604.0  11613.0  11626.0  100.0  32.0      1   \n",
       "2    11292.0  11297.0  ...  11284.0  11306.0  11336.0   31.0  29.0      0   \n",
       "3    11292.0  11297.0  ...  11284.0  11306.0  11336.0   31.0  29.0      0   \n",
       "4    11331.0  11333.0  ...  11279.0  11296.0  11318.0   31.0  28.0      0   \n",
       "..       ...      ...  ...      ...      ...      ...    ...   ...    ...   \n",
       "732  12339.0  12324.0  ...  12362.0  12367.0  12369.0   96.0  57.0      1   \n",
       "733  12429.0  12428.0  ...  12412.0  12413.0  12415.0   96.0  62.0      1   \n",
       "734  12412.0  12417.0  ...  12406.0  12402.0  12404.0   76.0  59.0      1   \n",
       "735  12334.0  12328.0  ...  12366.0  12375.0  12391.0   78.0  56.0      1   \n",
       "736  12337.0  12352.0  ...  12423.0  12419.0  12413.0   86.0  63.0      1   \n",
       "\n",
       "     second  thrid  Forth  label  \n",
       "0         1      0      0     CL  \n",
       "1         1      0      1     CL  \n",
       "2         1      0      1     CL  \n",
       "3         1      0      1     CL  \n",
       "4         1      0      1     CL  \n",
       "..      ...    ...    ...    ...  \n",
       "732       1      1      1   NROI  \n",
       "733       1      1      1   NROI  \n",
       "734       0      1      1   NROI  \n",
       "735       1      1      1   NROI  \n",
       "736       1      1      1   NROI  \n",
       "\n",
       "[737 rows x 232 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  pd.read_csv('../RawData/ROI_Pressure/Unnormed/year2_xy_map_unnormed.csv',index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43b61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data.iloc[:,:231]\n",
    "data_y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe7748f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>first</th>\n",
       "      <th>second</th>\n",
       "      <th>thrid</th>\n",
       "      <th>Forth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11133.0</td>\n",
       "      <td>11132.0</td>\n",
       "      <td>11130.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>11129.0</td>\n",
       "      <td>11130.0</td>\n",
       "      <td>11131.0</td>\n",
       "      <td>11134.0</td>\n",
       "      <td>11137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11040.0</td>\n",
       "      <td>11046.0</td>\n",
       "      <td>11056.0</td>\n",
       "      <td>11073.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11679.0</td>\n",
       "      <td>11676.0</td>\n",
       "      <td>11672.0</td>\n",
       "      <td>11668.0</td>\n",
       "      <td>11663.0</td>\n",
       "      <td>11658.0</td>\n",
       "      <td>11654.0</td>\n",
       "      <td>11648.0</td>\n",
       "      <td>11643.0</td>\n",
       "      <td>11638.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11598.0</td>\n",
       "      <td>11604.0</td>\n",
       "      <td>11613.0</td>\n",
       "      <td>11626.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11310.0</td>\n",
       "      <td>11302.0</td>\n",
       "      <td>11296.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11297.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11268.0</td>\n",
       "      <td>11284.0</td>\n",
       "      <td>11306.0</td>\n",
       "      <td>11336.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11310.0</td>\n",
       "      <td>11302.0</td>\n",
       "      <td>11296.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11287.0</td>\n",
       "      <td>11289.0</td>\n",
       "      <td>11292.0</td>\n",
       "      <td>11297.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11268.0</td>\n",
       "      <td>11284.0</td>\n",
       "      <td>11306.0</td>\n",
       "      <td>11336.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11383.0</td>\n",
       "      <td>11369.0</td>\n",
       "      <td>11358.0</td>\n",
       "      <td>11349.0</td>\n",
       "      <td>11343.0</td>\n",
       "      <td>11337.0</td>\n",
       "      <td>11333.0</td>\n",
       "      <td>11332.0</td>\n",
       "      <td>11331.0</td>\n",
       "      <td>11333.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11266.0</td>\n",
       "      <td>11279.0</td>\n",
       "      <td>11296.0</td>\n",
       "      <td>11318.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>12279.0</td>\n",
       "      <td>12299.0</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>12346.0</td>\n",
       "      <td>12353.0</td>\n",
       "      <td>12356.0</td>\n",
       "      <td>12353.0</td>\n",
       "      <td>12348.0</td>\n",
       "      <td>12339.0</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12351.0</td>\n",
       "      <td>12362.0</td>\n",
       "      <td>12367.0</td>\n",
       "      <td>12369.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>12389.0</td>\n",
       "      <td>12394.0</td>\n",
       "      <td>12407.0</td>\n",
       "      <td>12417.0</td>\n",
       "      <td>12421.0</td>\n",
       "      <td>12426.0</td>\n",
       "      <td>12428.0</td>\n",
       "      <td>12429.0</td>\n",
       "      <td>12429.0</td>\n",
       "      <td>12428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12411.0</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>12413.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>12419.0</td>\n",
       "      <td>12423.0</td>\n",
       "      <td>12420.0</td>\n",
       "      <td>12420.0</td>\n",
       "      <td>12419.0</td>\n",
       "      <td>12416.0</td>\n",
       "      <td>12415.0</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>12412.0</td>\n",
       "      <td>12417.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12404.0</td>\n",
       "      <td>12406.0</td>\n",
       "      <td>12402.0</td>\n",
       "      <td>12404.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>12318.0</td>\n",
       "      <td>12328.0</td>\n",
       "      <td>12336.0</td>\n",
       "      <td>12342.0</td>\n",
       "      <td>12344.0</td>\n",
       "      <td>12344.0</td>\n",
       "      <td>12342.0</td>\n",
       "      <td>12338.0</td>\n",
       "      <td>12334.0</td>\n",
       "      <td>12328.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12357.0</td>\n",
       "      <td>12366.0</td>\n",
       "      <td>12375.0</td>\n",
       "      <td>12391.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>12297.0</td>\n",
       "      <td>12310.0</td>\n",
       "      <td>12327.0</td>\n",
       "      <td>12331.0</td>\n",
       "      <td>12326.0</td>\n",
       "      <td>12310.0</td>\n",
       "      <td>12318.0</td>\n",
       "      <td>12324.0</td>\n",
       "      <td>12337.0</td>\n",
       "      <td>12352.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12426.0</td>\n",
       "      <td>12423.0</td>\n",
       "      <td>12419.0</td>\n",
       "      <td>12413.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3        4        5        6        7  \\\n",
       "0    11133.0  11132.0  11130.0  11129.0  11129.0  11129.0  11130.0  11131.0   \n",
       "1    11679.0  11676.0  11672.0  11668.0  11663.0  11658.0  11654.0  11648.0   \n",
       "2    11310.0  11302.0  11296.0  11292.0  11289.0  11287.0  11287.0  11289.0   \n",
       "3    11310.0  11302.0  11296.0  11292.0  11289.0  11287.0  11287.0  11289.0   \n",
       "4    11383.0  11369.0  11358.0  11349.0  11343.0  11337.0  11333.0  11332.0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "732  12279.0  12299.0  12324.0  12346.0  12353.0  12356.0  12353.0  12348.0   \n",
       "733  12389.0  12394.0  12407.0  12417.0  12421.0  12426.0  12428.0  12429.0   \n",
       "734  12419.0  12423.0  12420.0  12420.0  12419.0  12416.0  12415.0  12412.0   \n",
       "735  12318.0  12328.0  12336.0  12342.0  12344.0  12344.0  12342.0  12338.0   \n",
       "736  12297.0  12310.0  12327.0  12331.0  12326.0  12310.0  12318.0  12324.0   \n",
       "\n",
       "           8        9  ...      221      222      223      224    225   226  \\\n",
       "0    11134.0  11137.0  ...  11040.0  11046.0  11056.0  11073.0   94.0  17.0   \n",
       "1    11643.0  11638.0  ...  11598.0  11604.0  11613.0  11626.0  100.0  32.0   \n",
       "2    11292.0  11297.0  ...  11268.0  11284.0  11306.0  11336.0   31.0  29.0   \n",
       "3    11292.0  11297.0  ...  11268.0  11284.0  11306.0  11336.0   31.0  29.0   \n",
       "4    11331.0  11333.0  ...  11266.0  11279.0  11296.0  11318.0   31.0  28.0   \n",
       "..       ...      ...  ...      ...      ...      ...      ...    ...   ...   \n",
       "732  12339.0  12324.0  ...  12351.0  12362.0  12367.0  12369.0   96.0  57.0   \n",
       "733  12429.0  12428.0  ...  12411.0  12412.0  12413.0  12415.0   96.0  62.0   \n",
       "734  12412.0  12417.0  ...  12404.0  12406.0  12402.0  12404.0   76.0  59.0   \n",
       "735  12334.0  12328.0  ...  12357.0  12366.0  12375.0  12391.0   78.0  56.0   \n",
       "736  12337.0  12352.0  ...  12426.0  12423.0  12419.0  12413.0   86.0  63.0   \n",
       "\n",
       "     first  second  thrid  Forth  \n",
       "0        1       1      0      0  \n",
       "1        1       1      0      1  \n",
       "2        0       1      0      1  \n",
       "3        0       1      0      1  \n",
       "4        0       1      0      1  \n",
       "..     ...     ...    ...    ...  \n",
       "732      1       1      1      1  \n",
       "733      1       1      1      1  \n",
       "734      1       0      1      1  \n",
       "735      1       1      1      1  \n",
       "736      1       1      1      1  \n",
       "\n",
       "[737 rows x 231 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1830ba1",
   "metadata": {},
   "source": [
    "# Kmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2375a380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "       2, 0, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 1, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 1, 1, 1, 3, 1, 3, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 2, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 2,\n",
       "       0, 0, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 3, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2,\n",
       "       2, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 0, 2, 2, 2,\n",
       "       2, 1, 1, 1, 0, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 1, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 1, 3, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 3, 1, 1, 1, 2, 3, 2, 2, 1, 1, 2, 1, 3, 3, 2, 3, 3, 3, 1,\n",
       "       1, 3, 1, 1, 3, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2,\n",
       "       2, 3, 3, 3, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 1, 1, 1, 1, 3, 1, 3, 3, 3,\n",
       "       3, 3, 1, 3, 3, 0, 1, 1, 3, 3, 1, 3, 3, 1, 1, 1, 1, 3, 0, 1, 1, 1,\n",
       "       3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 1, 1, 1, 1, 1, 3, 0, 2, 3, 3, 2, 1, 0, 2, 2, 2, 2, 2, 3,\n",
       "       2, 2, 2, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 1, 3, 1, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters =4).fit(data_x)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fffcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../RawData/ROI_Pressure/Unnormed/year2_xy_unnormed.csv'\n",
    "results = []\n",
    "result_label = []\n",
    "for a in range (4):\n",
    "    for b in range (4):\n",
    "        for c in range (4):\n",
    "            for d in range (4):\n",
    "                data =  pd.read_csv(path,index_col=0)\n",
    "                data_y = data['label']\n",
    "                for i in range(0,data_y.shape[0]):\n",
    "                    if data_y[i] == 'CL':\n",
    "                        data_y[i]=a\n",
    "                    if data_y[i] == 'COH':\n",
    "                        data_y[i]=b\n",
    "                    if data_y[i] == 'COL':\n",
    "                        data_y[i]=c\n",
    "                    if data_y[i] == 'NROI':\n",
    "                        data_y[i]=d\n",
    "                    if(a==b or a==c or a==d or b==c or b==d or c==d):\n",
    "                        continue\n",
    "                    result = sum(1 for x,y in zip(data_y,kmeans.labels_) if x == y) / len(kmeans.labels_)\n",
    "                    results.append(result)\n",
    "                    result_label.append([a,b,c,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202b0f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max result is :0.4355495251017639and the label for CL, COL, COH, and NROI is :[2, 1, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "temp = results.copy()\n",
    "index = np.argsort(temp)\n",
    "print(\"max result is :\" + str(max(results))+ \"and the label for CL, COL, COH, and NROI is :\" + str(result_label[index[-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef92dd98",
   "metadata": {},
   "source": [
    "# Som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcaeba9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  pd.read_csv('../RawData/ROI_Pressure/Unnormed/year2_xy_map_unnormed.csv',index_col=0)\n",
    "data_x = data.iloc[:,:227]\n",
    "data_y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f6b5f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Data Normalization\n",
    "def minmax_scaler(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(data)\n",
    "    return scaled\n",
    "\n",
    "# Euclidean distance\n",
    "def e_distance(x,y):\n",
    "    return distance.euclidean(x,y)\n",
    "\n",
    "# Manhattan distance\n",
    "def m_distance(x,y):\n",
    "    return distance.cityblock(x,y)\n",
    "\n",
    "# Best Matching Unit search\n",
    "def winning_neuron(data, t, som, num_rows, num_cols):\n",
    "    winner = [0,0]\n",
    "    shortest_distance = np.sqrt(data.shape[1]) # initialise with max distance\n",
    "    input_data = data[t]\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            distance = e_distance(som[row][col], data[t])\n",
    "            if distance < shortest_distance: \n",
    "                shortest_distance = distance\n",
    "                winner = [row,col]\n",
    "    return winner\n",
    "\n",
    "# Learning rate and neighbourhood range calculation\n",
    "def decay(step, max_steps,max_learning_rate,max_m_dsitance):\n",
    "    coefficient = 1.0 - (np.float64(step)/max_steps)\n",
    "    learning_rate = coefficient*max_learning_rate\n",
    "    neighbourhood_range = ceil(coefficient * max_m_dsitance)\n",
    "    return learning_rate, neighbourhood_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "714694fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_rows = 10\n",
    "num_cols = 10\n",
    "max_m_dsitance = 4\n",
    "max_learning_rate = 0.5\n",
    "max_steps = int(50000)\n",
    "\n",
    "# num_nurons = 5*np.sqrt(train_x.shape[0])\n",
    "# grid_size = ceil(np.sqrt(num_nurons))\n",
    "# print(grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data\n",
    "train_x_norm = minmax_scaler(data_x) # normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09dd6001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5000\n",
      "Iteration:  10000\n",
      "Iteration:  15000\n",
      "Iteration:  20000\n",
      "Iteration:  25000\n",
      "Iteration:  30000\n",
      "Iteration:  35000\n",
      "Iteration:  40000\n",
      "Iteration:  45000\n",
      "Iteration:  50000\n",
      "SOM training completed\n"
     ]
    }
   ],
   "source": [
    "#main function\n",
    "\n",
    "# initialising self-organising map\n",
    "num_dims = train_x_norm.shape[1] # numnber of dimensions in the input data\n",
    "np.random.seed(40)\n",
    "som = np.random.random_sample(size=(num_rows, num_cols, num_dims)) # map construction\n",
    "\n",
    "# start training iterations\n",
    "for step in range(max_steps):\n",
    "    if (step+1) % 5000 == 0:\n",
    "        print(\"Iteration: \", step+1) # print out the current iteration for every 5k\n",
    "    learning_rate, neighbourhood_range = decay(step, max_steps,max_learning_rate,max_m_dsitance)\n",
    "\n",
    "    t = np.random.randint(0,high=train_x_norm.shape[0]) # random index of traing data\n",
    "    winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols)\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            if m_distance([row,col],winner) <= neighbourhood_range:\n",
    "                som[row][col] += learning_rate*(train_x_norm[t]-som[row][col]) #update neighbour's weight\n",
    "\n",
    "print(\"SOM training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d6e42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.59026253, 0.59190874, 0.59367874, ..., 0.6045202 ,\n",
       "         0.62713785, 0.176654  ],\n",
       "        [0.59965382, 0.59842872, 0.59771647, ..., 0.589554  ,\n",
       "         0.79632781, 0.15623891],\n",
       "        [0.58501681, 0.5825662 , 0.58071092, ..., 0.56809901,\n",
       "         0.81759047, 0.13815043],\n",
       "        ...,\n",
       "        [0.34121314, 0.33894456, 0.33685604, ..., 0.32198989,\n",
       "         0.8855405 , 0.25739367],\n",
       "        [0.23120295, 0.23027593, 0.2295343 , ..., 0.22050543,\n",
       "         0.79406705, 0.1422172 ],\n",
       "        [0.19425777, 0.19317014, 0.19230482, ..., 0.17959774,\n",
       "         0.72289251, 0.10101934]],\n",
       "\n",
       "       [[0.57531293, 0.57896952, 0.58256367, ..., 0.62770272,\n",
       "         0.55634835, 0.14953561],\n",
       "        [0.59887623, 0.59950022, 0.60041756, ..., 0.6100034 ,\n",
       "         0.72936998, 0.16109869],\n",
       "        [0.59131842, 0.5884245 , 0.58620551, ..., 0.57685279,\n",
       "         0.86053999, 0.16361948],\n",
       "        ...,\n",
       "        [0.31768655, 0.31652487, 0.31570408, ..., 0.31328475,\n",
       "         0.72079425, 0.23555803],\n",
       "        [0.27800401, 0.2779596 , 0.27813095, ..., 0.27739358,\n",
       "         0.76329528, 0.18199714],\n",
       "        [0.21716221, 0.21626791, 0.21557342, ..., 0.20591054,\n",
       "         0.7325669 , 0.13182253]],\n",
       "\n",
       "       [[0.58957402, 0.59420624, 0.59892966, ..., 0.65362856,\n",
       "         0.51379921, 0.13982048],\n",
       "        [0.60193952, 0.60414182, 0.60644312, ..., 0.6501991 ,\n",
       "         0.6732188 , 0.15737492],\n",
       "        [0.642456  , 0.63965774, 0.63752603, ..., 0.64361457,\n",
       "         0.89752307, 0.43365462],\n",
       "        ...,\n",
       "        [0.3745707 , 0.37404125, 0.3739526 , ..., 0.39372707,\n",
       "         0.55251933, 0.24732783],\n",
       "        [0.31637279, 0.31635435, 0.31655505, ..., 0.32679276,\n",
       "         0.65406077, 0.20868505],\n",
       "        [0.30376228, 0.30358445, 0.30361488, ..., 0.30841499,\n",
       "         0.61448228, 0.19757453]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.94982397, 0.95066795, 0.95196594, ..., 0.96878877,\n",
       "         0.77991132, 0.89699071],\n",
       "        [0.95667365, 0.95684368, 0.95718899, ..., 0.96586766,\n",
       "         0.73737994, 0.90053999],\n",
       "        [0.94144954, 0.94227748, 0.94360482, ..., 0.95432931,\n",
       "         0.553636  , 0.85679005],\n",
       "        ...,\n",
       "        [0.74653539, 0.74567476, 0.74516892, ..., 0.78469008,\n",
       "         0.35226076, 0.42842134],\n",
       "        [0.70376391, 0.69938146, 0.69525436, ..., 0.73832488,\n",
       "         0.30620354, 0.47393499],\n",
       "        [0.71062026, 0.70103166, 0.69202293, ..., 0.70968933,\n",
       "         0.23613728, 0.58340812]],\n",
       "\n",
       "       [[0.9420017 , 0.94395068, 0.94646208, ..., 0.98001862,\n",
       "         0.70368045, 0.89714639],\n",
       "        [0.9335605 , 0.93693216, 0.94093825, ..., 0.97609657,\n",
       "         0.58411225, 0.87158566],\n",
       "        [0.91136801, 0.91566624, 0.92039117, ..., 0.9680823 ,\n",
       "         0.3310833 , 0.82717007],\n",
       "        ...,\n",
       "        [0.71064812, 0.71400148, 0.71769715, ..., 0.77370387,\n",
       "         0.37376933, 0.21636087],\n",
       "        [0.73167529, 0.73312706, 0.73492046, ..., 0.77052812,\n",
       "         0.31530965, 0.39388825],\n",
       "        [0.73990768, 0.73656561, 0.73259594, ..., 0.75416584,\n",
       "         0.23094958, 0.70953464]],\n",
       "\n",
       "       [[0.92409872, 0.92839148, 0.9335938 , ..., 0.98250538,\n",
       "         0.60137539, 0.87552094],\n",
       "        [0.91429823, 0.91971693, 0.92600677, ..., 0.98273254,\n",
       "         0.54569268, 0.85609041],\n",
       "        [0.89292773, 0.89969564, 0.90708931, ..., 0.97110946,\n",
       "         0.40408223, 0.78131904],\n",
       "        ...,\n",
       "        [0.73588218, 0.7382055 , 0.74097626, ..., 0.78240315,\n",
       "         0.33923786, 0.25652125],\n",
       "        [0.76189319, 0.76198272, 0.76185842, ..., 0.77711624,\n",
       "         0.29566003, 0.46964523],\n",
       "        [0.76436129, 0.76341415, 0.76215415, ..., 0.77409996,\n",
       "         0.26762662, 0.59890173]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "som"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377fb84",
   "metadata": {},
   "source": [
    "# 0-Cl 1-COL 2-COH 3-NROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10facee1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    " \n",
    "# Creating a instance of label Encoder.\n",
    "le = LabelEncoder()\n",
    " \n",
    "# Using .fit_transform function to fit label\n",
    "# encoder and return encoded label\n",
    "data_y_label = le.fit_transform(data_y)\n",
    " \n",
    "# printing label\n",
    "data_y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a52640b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting labels\n",
    "\n",
    "label_data = data_y_label\n",
    "map = np.empty(shape=(num_rows, num_cols), dtype=object)\n",
    "\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        map[row][col] = [] # empty list to store the label\n",
    "\n",
    "for t in range(train_x_norm.shape[0]):\n",
    "    if (t+1) % 1000 == 0:\n",
    "        print(\"sample data: \", t+1)\n",
    "    winner = winning_neuron(train_x_norm, t, som, num_rows, num_cols)\n",
    "    map[winner[0]][winner[1]].append(label_data[t]) # label of winning neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "482cad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#after mapping x and y: 10 by 10 50000\n",
    "# construct label map\n",
    "label_map = np.zeros(shape=(num_rows, num_cols),dtype=np.int64)\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        label_list = map[row][col]\n",
    "        if len(label_list)==0:\n",
    "            label = 4\n",
    "        else:\n",
    "            label = max(label_list, key=label_list.count)\n",
    "        label_map[row][col] = label\n",
    "\n",
    "title = ('Iteration ' + str(max_steps))\n",
    "cmap = colors.ListedColormap(['tab:green', 'tab:red', 'tab:blue','tab:orange','tab:purple'])\n",
    "plt.imshow(label_map, cmap=cmap)\n",
    "plt.colorbar()\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c5f02ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "       [1, 2, 2, 2, 0, 4, 4, 0, 0, 0],\n",
       "       [1, 2, 2, 4, 2, 2, 2, 2, 0, 0],\n",
       "       [2, 2, 2, 2, 4, 2, 0, 2, 2, 2],\n",
       "       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "       [3, 2, 2, 0, 2, 2, 2, 2, 2, 2],\n",
       "       [3, 3, 2, 2, 2, 2, 2, 2, 4, 2],\n",
       "       [1, 2, 3, 2, 2, 3, 2, 1, 4, 2],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0-Cl 1-COL 2-COH 3-NROI\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f6391be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8534599728629579\n"
     ]
    }
   ],
   "source": [
    "data = minmax_scaler(data_x) # normalisation\n",
    "\n",
    "winner_labels = []\n",
    "\n",
    "for t in range(data.shape[0]):\n",
    "    winner = winning_neuron(data, t, som, num_rows, num_cols)\n",
    "    row = winner[0]\n",
    "    col = winner[1]\n",
    "    predicted = label_map[row][col]\n",
    "    winner_labels.append(predicted)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(data_y_label, np.array(winner_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c62e351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 2, 2, 3, 3, 3, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 2, 1, 0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 3, 3, 3, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(winner_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f120742",
   "metadata": {},
   "source": [
    "# Acc for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e148b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 178, 1: 161, 2: 327, 3: 71}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(data_y_label, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cb959c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_CL: 0.8764044943820225, acc_COL: 0.8944099378881988, acc_COH: 0.8593272171253823, acc_NROI: 0.676056338028169\n"
     ]
    }
   ],
   "source": [
    "#accuracy for each label\n",
    "#0-Cl 1-COL 2-COH 3-NROI\n",
    "acc_cl = sum(1 for x in winner_labels[:178] if x == 0) / 178\n",
    "acc_coh = sum(1 for x in winner_labels[178:505] if x == 2) / 327\n",
    "acc_col = sum(1 for x in winner_labels[505:666] if x == 1) / 161\n",
    "acc_nroi = sum(1 for x in winner_labels[666:] if x == 3) / 71\n",
    "print(f\"acc_CL: {acc_cl}, acc_COL: {acc_col}, acc_COH: {acc_coh}, acc_NROI: {acc_nroi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b83e688b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "among all the CL records:\n",
      "156 were classified as CL\n",
      "22 were classified as COH\n",
      "----------\n",
      "among all the COL records:\n",
      "5 were classified as CL\n",
      "144 were classified as COL\n",
      "10 were classified as COH\n",
      "2 were classified as NROI\n",
      "---------\n",
      "among all the COH records:\n",
      "25 were classified as CL\n",
      "2 were classified as COL\n",
      "281 were classified as COH\n",
      "19 were classified as NROI\n",
      "---------\n",
      "among all the NROI records:\n",
      "4 were classified as COL\n",
      "19 were classified as COH\n",
      "48 were classified as NROI\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(winner_labels[:178], return_counts=True)\n",
    "print('among all the CL records:')\n",
    "for i in range(2):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')\n",
    "print(\"----------\")\n",
    "\n",
    "unique, counts = np.unique(winner_labels[505:666], return_counts=True)\n",
    "print('among all the COL records:')\n",
    "for i in range(4):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')\n",
    "print(\"---------\")\n",
    "\n",
    "\n",
    "unique, counts = np.unique(winner_labels[178:505], return_counts=True)\n",
    "print('among all the COH records:')\n",
    "for i in range(4):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')\n",
    "    \n",
    "print(\"---------\")\n",
    "    \n",
    "unique, counts = np.unique(winner_labels[666:], return_counts=True)\n",
    "print('among all the NROI records:')\n",
    "for i in range(3):\n",
    "    temp = unique[i]\n",
    "    if temp == 0:\n",
    "        temp = 'CL'\n",
    "    if temp == 1:\n",
    "        temp = 'COL'\n",
    "    if temp == 2:\n",
    "        temp = 'COH'\n",
    "    if temp == 3:\n",
    "        temp = 'NROI'\n",
    "    print(f'{counts[i]} were classified as {temp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7ba05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
